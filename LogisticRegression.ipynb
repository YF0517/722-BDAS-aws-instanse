{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8bb1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25d24c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/transformed.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64b15cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- revenue: integer (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- vote_count: integer (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- production_country: string (nullable = true)\n",
      " |-- popularity_rank: string (nullable = true)\n",
      " |-- risk: string (nullable = true)\n",
      "\n",
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+\n",
      "|   budget|popularity|   revenue|runtime|vote_count|          genre|release_date|production_country|popularity_rank|risk|\n",
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+\n",
      "|300000000|139.082615| 961000000|    169|      4500|         Action|  2007-05-19|      united_state|           high| low|\n",
      "|245000000|107.376788| 880674609|    148|      4466|         Action|  2015-10-26|            others|           high| low|\n",
      "|250000000| 112.31295|1084939099|    165|      9106|         Action|  2012-07-16|      united_state|           high| low|\n",
      "|260000000| 43.926995| 284139100|    132|      2124|         Action|  2012-03-07|      united_state|           high| low|\n",
      "|260000000| 48.681969| 591794936|    100|      3330|      Animation|  2010-11-24|      united_state|           high| low|\n",
      "|280000000|134.279229|1405403694|    141|      6767|         Action|  2015-04-22|      united_state|           high| low|\n",
      "|250000000| 98.885637| 933959197|    153|      5293|      Advanture|  2009-07-07|            others|           high| low|\n",
      "|250000000|155.790452| 873260194|    151|      7004|         Action|  2016-03-23|      united_state|           high| low|\n",
      "|270000000| 57.925623| 391081192|    154|      1400|         Action|  2006-06-28|      united_state|           high| low|\n",
      "|200000000|107.928811| 586090727|    106|      2965|      Advanture|  2008-10-30|            others|           high| low|\n",
      "|200000000|145.847379|1065659812|    151|      5246|      Advanture|  2006-06-20|            others|           high| low|\n",
      "|255000000| 49.046956|  89289910|    149|      2311|         Action|  2013-07-03|      united_state|           high|high|\n",
      "|225000000| 99.398009| 662845518|    143|      6359|         Action|  2013-06-12|            others|           high| low|\n",
      "|225000000| 53.978602| 419651413|    150|      1630|      Advanture|  2008-05-15|            others|           high| low|\n",
      "|220000000|144.448633|1519557910|    143|     11776|Science fiction|  2012-04-25|      united_state|           high| low|\n",
      "|380000000|135.413856|1045713802|    136|      4948|      Advanture|  2011-05-14|      united_state|           high| low|\n",
      "|225000000| 52.035179| 624026776|    106|      4160|         Action|  2012-05-23|      united_state|           high| low|\n",
      "|250000000|120.965743| 956019788|    144|      4760|         Action|  2014-12-10|            others|           high| low|\n",
      "|215000000| 89.866276| 752215857|    136|      6586|         Action|  2012-06-27|      united_state|           high| low|\n",
      "|200000000| 37.668301| 310669540|    140|      1398|         Action|  2010-05-12|            others|           high| low|\n",
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optionally, rename columns for better clarity\n",
    "df = df.withColumnRenamed(\"_c0\", \"budget\") \\\n",
    "       .withColumnRenamed(\"_c1\", \"popularity\") \\\n",
    "       .withColumnRenamed(\"_c2\", \"revenue\") \\\n",
    "       .withColumnRenamed(\"_c3\", \"runtime\") \\\n",
    "       .withColumnRenamed(\"_c4\", \"vote_count\") \\\n",
    "       .withColumnRenamed(\"_c5\", \"genre\") \\\n",
    "       .withColumnRenamed(\"_c6\", \"release_date\") \\\n",
    "       .withColumnRenamed(\"_c7\", \"production_country\")\\\n",
    "       .withColumnRenamed(\"_c8\", \"popularity_rank\")\\\n",
    "       .withColumnRenamed(\"_c9\", \"risk\")\n",
    "# Let's get an idea of what the data looks like. \n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6615b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# Convert categorical columns into numerical representations\n",
    "indexer_genre = StringIndexer(inputCol=\"genre\", outputCol=\"genre_index\")\n",
    "indexer_country = StringIndexer(inputCol=\"production_country\", outputCol=\"country_index\")\n",
    "indexer_risk = StringIndexer(inputCol=\"risk\", outputCol=\"risk_index\")\n",
    "indexer_rank = StringIndexer(inputCol=\"popularity_rank\", outputCol=\"rank_index\")\n",
    "\n",
    "# Apply StringIndexer transformations\n",
    "df = indexer_genre.fit(df).transform(df)\n",
    "df = indexer_country.fit(df).transform(df)\n",
    "df = indexer_risk.fit(df).transform(df)\n",
    "df = indexer_rank.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51437567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+-----------+-------------+----------+----------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+\n",
      "|   budget|popularity|   revenue|runtime|vote_count|          genre|release_date|production_country|popularity_rank|risk|genre_index|country_index|risk_index|rank_index|genre_1|genre_2|genre_3|genre_4|genre_5|genre_6|genre_7|genre_8|genre_9|genre_10|genre_11|\n",
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+-----------+-------------+----------+----------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+\n",
      "|300000000|139.082615| 961000000|    169|      4500|         Action|  2007-05-19|      united_state|           high| low|        1.0|          0.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|245000000|107.376788| 880674609|    148|      4466|         Action|  2015-10-26|            others|           high| low|        1.0|          1.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|250000000| 112.31295|1084939099|    165|      9106|         Action|  2012-07-16|      united_state|           high| low|        1.0|          0.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|260000000| 43.926995| 284139100|    132|      2124|         Action|  2012-03-07|      united_state|           high| low|        1.0|          0.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|260000000| 48.681969| 591794936|    100|      3330|      Animation|  2010-11-24|      united_state|           high| low|        6.0|          0.0|       0.0|       0.0|      0|      0|      0|      0|      0|      1|      0|      0|      0|       0|       0|\n",
      "|280000000|134.279229|1405403694|    141|      6767|         Action|  2015-04-22|      united_state|           high| low|        1.0|          0.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|250000000| 98.885637| 933959197|    153|      5293|      Advanture|  2009-07-07|            others|           high| low|        3.0|          1.0|       0.0|       0.0|      0|      0|      1|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|250000000|155.790452| 873260194|    151|      7004|         Action|  2016-03-23|      united_state|           high| low|        1.0|          0.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|270000000| 57.925623| 391081192|    154|      1400|         Action|  2006-06-28|      united_state|           high| low|        1.0|          0.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|200000000|107.928811| 586090727|    106|      2965|      Advanture|  2008-10-30|            others|           high| low|        3.0|          1.0|       0.0|       0.0|      0|      0|      1|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|200000000|145.847379|1065659812|    151|      5246|      Advanture|  2006-06-20|            others|           high| low|        3.0|          1.0|       0.0|       0.0|      0|      0|      1|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|255000000| 49.046956|  89289910|    149|      2311|         Action|  2013-07-03|      united_state|           high|high|        1.0|          0.0|       1.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|225000000| 99.398009| 662845518|    143|      6359|         Action|  2013-06-12|            others|           high| low|        1.0|          1.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|225000000| 53.978602| 419651413|    150|      1630|      Advanture|  2008-05-15|            others|           high| low|        3.0|          1.0|       0.0|       0.0|      0|      0|      1|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|220000000|144.448633|1519557910|    143|     11776|Science fiction|  2012-04-25|      united_state|           high| low|        4.0|          0.0|       0.0|       0.0|      0|      0|      0|      1|      0|      0|      0|      0|      0|       0|       0|\n",
      "|380000000|135.413856|1045713802|    136|      4948|      Advanture|  2011-05-14|      united_state|           high| low|        3.0|          0.0|       0.0|       0.0|      0|      0|      1|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|225000000| 52.035179| 624026776|    106|      4160|         Action|  2012-05-23|      united_state|           high| low|        1.0|          0.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|250000000|120.965743| 956019788|    144|      4760|         Action|  2014-12-10|            others|           high| low|        1.0|          1.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|215000000| 89.866276| 752215857|    136|      6586|         Action|  2012-06-27|      united_state|           high| low|        1.0|          0.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "|200000000| 37.668301| 310669540|    140|      1398|         Action|  2010-05-12|            others|           high| low|        1.0|          1.0|       0.0|       0.0|      1|      0|      0|      0|      0|      0|      0|      0|      0|       0|       0|\n",
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+-----------+-------------+----------+----------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, lit\n",
    "\n",
    "# Get unique genre numbers\n",
    "unique_genre_numbers = df.select(\"genre_index\").distinct().count()\n",
    "\n",
    "# Iterate over each unique genre number and create a new column with 1 for true and 0 for false\n",
    "for i in range(1, unique_genre_numbers + 1):\n",
    "    genre_col = f\"genre_{i}\"\n",
    "    df = df.withColumn(genre_col, when(col(\"genre_index\") == i, lit(1)).otherwise(lit(0)))\n",
    "\n",
    "# Show the DataFrame with encoded genres\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c76e3f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "genre_1: 1.4027493451462023\n",
      "genre_2: -1.2187117230023452\n",
      "genre_3: -1.2090317385766216\n",
      "genre_4: -1.1824881514556438\n",
      "genre_5: 3.15134377543869\n",
      "genre_6: 2.9154125934420714\n",
      "genre_7: 1.8627111562701237\n",
      "genre_8: -1.171063351130465\n",
      "genre_9: 7.230150469947778\n",
      "genre_10: 5.506446974005068\n",
      "genre_11: 0.0\n",
      "Intercept: -6.124623535270408\n",
      "Test Area Under ROC = 0.7334905660377359\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"LogisticRegressionExample\").getOrCreate()\n",
    "\n",
    "# List of feature column names\n",
    "all_feature_columns = ['genre_1', 'genre_2', 'genre_3', 'genre_4', 'genre_5','genre_6', 'genre_7', 'genre_8', 'genre_9', 'genre_10', 'genre_11']\n",
    "\n",
    "# Assemble features into a single vector\n",
    "assembler = VectorAssembler(inputCols=all_feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(df)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = data.randomSplit([0.7, 0.3], seed=1234)\n",
    "\n",
    "# Create and train the Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"rank_index\", maxIter=10)\n",
    "model = lr.fit(train_data)\n",
    "\n",
    "# Print the coefficients and intercept of the model\n",
    "print(\"Coefficients:\")\n",
    "coefficients = model.coefficients\n",
    "intercept = model.intercept\n",
    "for i, feature in enumerate(all_feature_columns):\n",
    "    print(f\"{feature}: {coefficients[i]}\")\n",
    "\n",
    "print(f\"Intercept: {intercept}\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"rank_index\", rawPredictionCol=\"rawPrediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Area Under ROC = {accuracy}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
