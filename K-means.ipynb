{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f23d9ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32dd705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/transformed.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "938e8e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- revenue: integer (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- vote_count: integer (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- production_country: string (nullable = true)\n",
      " |-- popularity_rank: string (nullable = true)\n",
      " |-- risk: string (nullable = true)\n",
      "\n",
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+\n",
      "|   budget|popularity|   revenue|runtime|vote_count|          genre|release_date|production_country|popularity_rank|risk|\n",
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+\n",
      "|300000000|139.082615| 961000000|    169|      4500|         Action|  2007-05-19|      united_state|           high| low|\n",
      "|245000000|107.376788| 880674609|    148|      4466|         Action|  2015-10-26|            others|           high| low|\n",
      "|250000000| 112.31295|1084939099|    165|      9106|         Action|  2012-07-16|      united_state|           high| low|\n",
      "|260000000| 43.926995| 284139100|    132|      2124|         Action|  2012-03-07|      united_state|           high| low|\n",
      "|260000000| 48.681969| 591794936|    100|      3330|      Animation|  2010-11-24|      united_state|           high| low|\n",
      "|280000000|134.279229|1405403694|    141|      6767|         Action|  2015-04-22|      united_state|           high| low|\n",
      "|250000000| 98.885637| 933959197|    153|      5293|      Advanture|  2009-07-07|            others|           high| low|\n",
      "|250000000|155.790452| 873260194|    151|      7004|         Action|  2016-03-23|      united_state|           high| low|\n",
      "|270000000| 57.925623| 391081192|    154|      1400|         Action|  2006-06-28|      united_state|           high| low|\n",
      "|200000000|107.928811| 586090727|    106|      2965|      Advanture|  2008-10-30|            others|           high| low|\n",
      "|200000000|145.847379|1065659812|    151|      5246|      Advanture|  2006-06-20|            others|           high| low|\n",
      "|255000000| 49.046956|  89289910|    149|      2311|         Action|  2013-07-03|      united_state|           high|high|\n",
      "|225000000| 99.398009| 662845518|    143|      6359|         Action|  2013-06-12|            others|           high| low|\n",
      "|225000000| 53.978602| 419651413|    150|      1630|      Advanture|  2008-05-15|            others|           high| low|\n",
      "|220000000|144.448633|1519557910|    143|     11776|Science fiction|  2012-04-25|      united_state|           high| low|\n",
      "|380000000|135.413856|1045713802|    136|      4948|      Advanture|  2011-05-14|      united_state|           high| low|\n",
      "|225000000| 52.035179| 624026776|    106|      4160|         Action|  2012-05-23|      united_state|           high| low|\n",
      "|250000000|120.965743| 956019788|    144|      4760|         Action|  2014-12-10|            others|           high| low|\n",
      "|215000000| 89.866276| 752215857|    136|      6586|         Action|  2012-06-27|      united_state|           high| low|\n",
      "|200000000| 37.668301| 310669540|    140|      1398|         Action|  2010-05-12|            others|           high| low|\n",
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optionally, rename columns for better clarity\n",
    "df = df.withColumnRenamed(\"_c0\", \"budget\") \\\n",
    "       .withColumnRenamed(\"_c1\", \"popularity\") \\\n",
    "       .withColumnRenamed(\"_c2\", \"revenue\") \\\n",
    "       .withColumnRenamed(\"_c3\", \"runtime\") \\\n",
    "       .withColumnRenamed(\"_c4\", \"vote_count\") \\\n",
    "       .withColumnRenamed(\"_c5\", \"genre\") \\\n",
    "       .withColumnRenamed(\"_c6\", \"release_date\") \\\n",
    "       .withColumnRenamed(\"_c7\", \"production_country\")\\\n",
    "       .withColumnRenamed(\"_c8\", \"popularity_rank\")\\\n",
    "       .withColumnRenamed(\"_c9\", \"risk\")\n",
    "# Let's get an idea of what the data looks like. \n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e1e687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# Convert categorical columns into numerical representations\n",
    "indexer_genre = StringIndexer(inputCol=\"genre\", outputCol=\"genre_index\")\n",
    "indexer_country = StringIndexer(inputCol=\"production_country\", outputCol=\"country_index\")\n",
    "indexer_risk = StringIndexer(inputCol=\"risk\", outputCol=\"risk_index\")\n",
    "indexer_rank = StringIndexer(inputCol=\"popularity_rank\", outputCol=\"rank_index\")\n",
    "\n",
    "# Apply StringIndexer transformations\n",
    "df = indexer_genre.fit(df).transform(df)\n",
    "df = indexer_country.fit(df).transform(df)\n",
    "df = indexer_risk.fit(df).transform(df)\n",
    "df = indexer_rank.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f2051c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.7217369713952484\n",
      "+----------+------------------+-------------------+-------------------+--------------------+\n",
      "|prediction|  mean_genre_index| mean_country_index|    mean_risk_index|     mean_rank_index|\n",
      "+----------+------------------+-------------------+-------------------+--------------------+\n",
      "|         1|0.3193717277486911|0.48616305160807777| 0.2610321615557218|0.005983545250560957|\n",
      "|         2|6.9033613445378155| 0.4789915966386555|0.24789915966386555|0.037815126050420166|\n",
      "|         0|3.1424100156494523| 0.5226917057902973|  0.215962441314554| 0.00782472613458529|\n",
      "+----------+------------------+-------------------+-------------------+--------------------+\n",
      "\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1| 1337|\n",
      "|         2|  238|\n",
      "|         0|  639|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KMeans Clustering\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load data\n",
    "data = df\n",
    "\n",
    "# Preprocess data and create feature vector\n",
    "feature_cols = ['genre_index', 'country_index', 'risk_index', 'rank_index']\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Train K-means model\n",
    "kmeans = KMeans(k=3, seed=1)  # Specify the number of clusters (k)\n",
    "model = kmeans.fit(data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(data)\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(f\"Silhouette with squared euclidean distance = {silhouette}\")\n",
    "\n",
    "\n",
    "\n",
    "# Compare clusters by aggregating features\n",
    "cluster_comparison = predictions.groupby(\"prediction\").agg(\n",
    "    F.mean(\"genre_index\").alias(\"mean_genre_index\"),\n",
    "    F.mean(\"country_index\").alias(\"mean_country_index\"),\n",
    "    F.mean(\"risk_index\").alias(\"mean_risk_index\"),\n",
    "    F.mean(\"rank_index\").alias(\"mean_rank_index\")\n",
    ")\n",
    "\n",
    "# Show cluster comparison\n",
    "cluster_comparison.show()\n",
    "\n",
    "# Calculate cluster sizes\n",
    "cluster_sizes = predictions.groupBy(\"prediction\").count()\n",
    "\n",
    "# Show cluster sizes\n",
    "cluster_sizes.show()\n",
    "\n",
    "\n",
    "\n",
    "# Save or export results\n",
    "# predictions.select(\"genre_index\", \"country_index\", \"risk_index\", \"rank_index\", \"prediction\") \\\n",
    "#     .write.csv(\"data/kmeans_predictions.csv\", header=True)\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634dc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spark.read.csv('data/kmeans_predictions.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3974ce1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+----------+----------+\n",
      "|        _c0|          _c1|       _c2|       _c3|       _c4|\n",
      "+-----------+-------------+----------+----------+----------+\n",
      "|genre_index|country_index|risk_index|rank_index|prediction|\n",
      "|        1.0|          0.0|       0.0|       0.0|         1|\n",
      "|        1.0|          1.0|       0.0|       0.0|         1|\n",
      "|        1.0|          0.0|       0.0|       0.0|         1|\n",
      "|        1.0|          0.0|       0.0|       0.0|         1|\n",
      "|        6.0|          0.0|       0.0|       0.0|         2|\n",
      "|        1.0|          0.0|       0.0|       0.0|         1|\n",
      "|        3.0|          1.0|       0.0|       0.0|         0|\n",
      "|        1.0|          0.0|       0.0|       0.0|         1|\n",
      "|        1.0|          0.0|       0.0|       0.0|         1|\n",
      "|        3.0|          1.0|       0.0|       0.0|         0|\n",
      "|        3.0|          1.0|       0.0|       0.0|         0|\n",
      "|        1.0|          0.0|       1.0|       0.0|         1|\n",
      "|        1.0|          1.0|       0.0|       0.0|         1|\n",
      "|        3.0|          1.0|       0.0|       0.0|         0|\n",
      "|        4.0|          0.0|       0.0|       0.0|         0|\n",
      "|        3.0|          0.0|       0.0|       0.0|         0|\n",
      "|        1.0|          0.0|       0.0|       0.0|         1|\n",
      "|        1.0|          1.0|       0.0|       0.0|         1|\n",
      "|        1.0|          0.0|       0.0|       0.0|         1|\n",
      "+-----------+-------------+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
