{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a874afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "62f4750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset1 = spark.read.csv('data/tmdb_5000_movies_fixed1_fix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "04d28a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, rename columns for better clarity\n",
    "df_dataset1 = df_dataset1.withColumnRenamed(\"_c0\", \"budget\") \\\n",
    "       .withColumnRenamed(\"_c1\", \"id\") \\\n",
    "       .withColumnRenamed(\"_c2\", \"original_language\") \\\n",
    "       .withColumnRenamed(\"_c3\", \"popularity\") \\\n",
    "       .withColumnRenamed(\"_c4\", \"revenue\") \\\n",
    "       .withColumnRenamed(\"_c5\", \"runtime\") \\\n",
    "       .withColumnRenamed(\"_c6\", \"status\") \\\n",
    "       .withColumnRenamed(\"_c7\", \"title\") \\\n",
    "       .withColumnRenamed(\"_c8\", \"vote_average\") \\\n",
    "       .withColumnRenamed(\"_c9\", \"vote_count\") \\\n",
    "       .withColumnRenamed(\"_c10\", \"genre\") \\\n",
    "       .withColumnRenamed(\"_c11\", \"release_date\") \\\n",
    "       .withColumnRenamed(\"_c12\", \"production_country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e63e9ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- revenue: integer (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: double (nullable = true)\n",
      " |-- vote_count: integer (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- release_date: date (nullable = true)\n",
      " |-- production_country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date\n",
    "from pyspark.sql.types import IntegerType, DoubleType, DateType\n",
    "\n",
    "# Convert columns to the desired data types\n",
    "df_dataset1 = df_dataset1.withColumn(\"budget\", df_dataset1[\"budget\"].cast(IntegerType()))\n",
    "df_dataset1 = df_dataset1.withColumn(\"id\", df_dataset1[\"id\"].cast(IntegerType()))\n",
    "df_dataset1 = df_dataset1.withColumn(\"popularity\", df_dataset1[\"popularity\"].cast(DoubleType()))\n",
    "df_dataset1 = df_dataset1.withColumn(\"revenue\", df_dataset1[\"revenue\"].cast(IntegerType()))\n",
    "df_dataset1 = df_dataset1.withColumn(\"runtime\", df_dataset1[\"runtime\"].cast(IntegerType()))\n",
    "df_dataset1 = df_dataset1.withColumn(\"vote_average\", df_dataset1[\"vote_average\"].cast(DoubleType()))\n",
    "df_dataset1 = df_dataset1.withColumn(\"vote_count\", df_dataset1[\"vote_count\"].cast(IntegerType()))\n",
    "df_dataset1 = df_dataset1.withColumn(\"release_date\", to_date(df_dataset1[\"release_date\"], \"yyyy-MM-dd\"))\n",
    "\n",
    "# Print the updated schema\n",
    "df_dataset1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8de6b0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|summary|\n",
      "+-------+\n",
      "|  count|\n",
      "|   mean|\n",
      "| stddev|\n",
      "|    min|\n",
      "|    max|\n",
      "+-------+\n",
      "\n",
      "+-------+-------------------+-----------------+-----------------+------------------+-------------------+------------+------+-------+-----------------+-----------------+-----+------------------+\n",
      "|summary|             budget|               id|original_language|        popularity|            revenue|     runtime|status|  title|     vote_average|       vote_count|genre|production_country|\n",
      "+-------+-------------------+-----------------+-----------------+------------------+-------------------+------------+------+-------+-----------------+-----------------+-----+------------------+\n",
      "|  count|               2562|             2562|             2562|              2562|               2561|        2560|  2562|   2562|             2562|             2562| 2543|              2562|\n",
      "|   mean|3.253420255542545E7|93351.39071038252|             null|24.567019620999194|9.112642305583756E7|104.64296875|  null|960.625|5.959289617486325|816.7498048399688| null|              null|\n",
      "+-------+-------------------+-----------------+-----------------+------------------+-------------------+------------+------+-------+-----------------+-----------------+-----+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter DataFrame to include only rows with release_date after '2005-01-01'\n",
    "df_dataset1_clean = df_dataset1.filter(col(\"release_date\") > '2005-01-01')\n",
    "\n",
    "# Describe the release_date column of the cleaned DataFrame\n",
    "df_dataset1_clean.select(\"release_date\").describe().show()\n",
    "\n",
    "# Show the cleaned DataFrame\n",
    "df_dataset1_clean.describe().show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "696dbc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|              budget|\n",
      "+-------+--------------------+\n",
      "|  count|                1649|\n",
      "|   mean| 4.827350042146756E7|\n",
      "| stddev|5.1542107119679816E7|\n",
      "|    min|               65000|\n",
      "|    max|           380000000|\n",
      "+-------+--------------------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|            revenue|\n",
      "+-------+-------------------+\n",
      "|  count|               1649|\n",
      "|   mean|1.400165642953305E8|\n",
      "| stddev|2.054395901950808E8|\n",
      "|    min|              53086|\n",
      "|    max|         1519557910|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter DataFrame to drop rows where budget or revenue is less than 50000\n",
    "df_dataset1_clean = df_dataset1_clean.filter((col(\"budget\") >= 50000) & (col(\"revenue\") >= 50000))\n",
    "\n",
    "# Describe the budget column of the cleaned DataFrame\n",
    "df_dataset1_clean.select(\"budget\").describe().show()\n",
    "df_dataset1_clean.select(\"revenue\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5bb1d16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+\n",
      "|   budget|popularity|   revenue|runtime|vote_average|vote_count|          genre|release_date|production_country|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+\n",
      "|300000000|139.082615| 961000000|    169|         6.9|      4500|         Action|  2007-05-19|      united_state|\n",
      "|245000000|107.376788| 880674609|    148|         6.3|      4466|         Action|  2015-10-26|    united_kingdom|\n",
      "|250000000| 112.31295|1084939099|    165|         7.6|      9106|         Action|  2012-07-16|      united_state|\n",
      "|260000000| 43.926995| 284139100|    132|         6.1|      2124|         Action|  2012-03-07|               USA|\n",
      "|260000000| 48.681969| 591794936|    100|         7.4|      3330|      Animation|  2010-11-24|      united_state|\n",
      "|280000000|134.279229|1405403694|    141|         7.3|      6767|         Action|  2015-04-22|      united_state|\n",
      "|250000000| 98.885637| 933959197|    153|         7.4|      5293|      Advanture|  2009-07-07|    united_kingdom|\n",
      "|250000000|155.790452| 873260194|    151|         5.7|      7004|         Action|  2016-03-23|      united_state|\n",
      "|270000000| 57.925623| 391081192|    154|         5.4|      1400|         Action|  2006-06-28|      united_state|\n",
      "|200000000|107.928811| 586090727|    106|         6.1|      2965|      Advanture|  2008-10-30|    united_kingdom|\n",
      "|200000000|145.847379|1065659812|    151|         7.0|      5246|      Advanture|  2006-06-20|           jamaica|\n",
      "|255000000| 49.046956|  89289910|    149|         5.9|      2311|         Action|  2013-07-03|      united_state|\n",
      "|225000000| 99.398009| 662845518|    143|         6.5|      6359|         Action|  2013-06-12|    united_kingdom|\n",
      "|225000000| 53.978602| 419651413|    150|         6.3|      1630|      Advanture|  2008-05-15|    czech republic|\n",
      "|220000000|144.448633|1519557910|    143|         7.4|     11776|Science fiction|  2012-04-25|               USA|\n",
      "|380000000|135.413856|1045713802|    136|         6.4|      4948|      Advanture|  2011-05-14|      united_state|\n",
      "|225000000| 52.035179| 624026776|    106|         6.2|      4160|         Action|  2012-05-23|      united_state|\n",
      "|250000000|120.965743| 956019788|    144|         7.1|      4760|         Action|  2014-12-10|       new_zealand|\n",
      "|215000000| 89.866276| 752215857|    136|         6.5|      6586|         Action|  2012-06-27|      united_state|\n",
      "|200000000| 37.668301| 310669540|    140|         6.2|      1398|         Action|  2010-05-12|    united_kingdom|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify columns to drop\n",
    "columns_to_drop = [\"id\", \"original_language\", \"status\", \"title\"]\n",
    "\n",
    "# Drop the specified columns\n",
    "df_dataset1_clean = df_dataset1_clean.drop(*columns_to_drop)\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df_dataset1_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2d2bc363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|production_country|\n",
      "+------------------+\n",
      "|           finland|\n",
      "|            greece|\n",
      "|            israel|\n",
      "|             #REF!|\n",
      "|    czech republic|\n",
      "|             malta|\n",
      "|             japan|\n",
      "|           austria|\n",
      "|        luxembourg|\n",
      "|          thailand|\n",
      "|             india|\n",
      "|          hongkong|\n",
      "|         australia|\n",
      "|       united_arab|\n",
      "|         indonesia|\n",
      "|       new_zealand|\n",
      "|            brazil|\n",
      "|           jamaica|\n",
      "|       netherlands|\n",
      "|      south_africa|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in the 'production_country' column\n",
    "unique_values = df_dataset1_clean.select('production_country').distinct()\n",
    "\n",
    "# Show unique values\n",
    "unique_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "82d64c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|production_country|\n",
      "+------------------+\n",
      "|           finland|\n",
      "|            greece|\n",
      "|            israel|\n",
      "|    czech republic|\n",
      "|             malta|\n",
      "|             japan|\n",
      "|           austria|\n",
      "|        luxembourg|\n",
      "|          thailand|\n",
      "|             india|\n",
      "|          hongkong|\n",
      "|         australia|\n",
      "|       united_arab|\n",
      "|         indonesia|\n",
      "|       new_zealand|\n",
      "|            brazil|\n",
      "|           jamaica|\n",
      "|       netherlands|\n",
      "|      south_africa|\n",
      "|            canada|\n",
      "|            france|\n",
      "|        swizerland|\n",
      "|           iceland|\n",
      "|    united_kingdom|\n",
      "|         argentina|\n",
      "|               USA|\n",
      "|       south_korea|\n",
      "|           germany|\n",
      "|            russia|\n",
      "|             italy|\n",
      "|           ireland|\n",
      "|           belgium|\n",
      "|           romania|\n",
      "|            norway|\n",
      "|           denmark|\n",
      "|           bahamas|\n",
      "|       philippines|\n",
      "|             china|\n",
      "|          bulgaria|\n",
      "|      united_state|\n",
      "|           hungary|\n",
      "|             spain|\n",
      "|            mexico|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Calculate the mode of the production_country column\n",
    "mode_production_country = df_dataset1_clean.select('production_country') \\\n",
    "                                           .groupBy('production_country') \\\n",
    "                                           .count() \\\n",
    "                                           .orderBy(col('count').desc()) \\\n",
    "                                           .limit(1) \\\n",
    "                                           .collect()[0][0]\n",
    "\n",
    "# Replace #REF! with the mode\n",
    "df_dataset1_clean = df_dataset1_clean.withColumn('production_country', \n",
    "                                                 when(col('production_country') == '#REF!', mode_production_country)\n",
    "                                                 .otherwise(col('production_country')))\n",
    "\n",
    "# Check unique values in the 'production_country' column\n",
    "unique_values = df_dataset1_clean.select('production_country').distinct()\n",
    "\n",
    "# Show unique values\n",
    "unique_values.show(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "275bf774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------+-------+------------+----------+-----+------------+------------------+\n",
      "|budget|popularity|revenue|runtime|vote_average|vote_count|genre|release_date|production_country|\n",
      "+------+----------+-------+-------+------------+----------+-----+------------+------------------+\n",
      "+------+----------+-------+-------+------------+----------+-----+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filter rows with any NaN values\n",
    "rows_with_nan = df_dataset1_clean.filter(\n",
    "    (col(\"budget\").isNull()) |\n",
    "    (col(\"revenue\").isNull()) |\n",
    "    (col(\"runtime\").isNull()) |\n",
    "    (col(\"vote_average\").isNull()) |\n",
    "    (col(\"vote_count\").isNull()) |\n",
    "    (col(\"release_date\").isNull()) |\n",
    "    (col(\"production_country\").isNull()) |\n",
    "    (col(\"genre\").isNull())\n",
    ")\n",
    "\n",
    "# Show the rows with NaN values\n",
    "rows_with_nan.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bc9fad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|production_country|\n",
      "+------------------+\n",
      "|           finland|\n",
      "|            greece|\n",
      "|            israel|\n",
      "|    czech republic|\n",
      "|             malta|\n",
      "|             japan|\n",
      "|           austria|\n",
      "|        luxembourg|\n",
      "|          thailand|\n",
      "|             india|\n",
      "|          hongkong|\n",
      "|         australia|\n",
      "|       united_arab|\n",
      "|         indonesia|\n",
      "|       new_zealand|\n",
      "|            brazil|\n",
      "|           jamaica|\n",
      "|       netherlands|\n",
      "|      south_africa|\n",
      "|            canada|\n",
      "|            france|\n",
      "|        swizerland|\n",
      "|           iceland|\n",
      "|    united_kingdom|\n",
      "|         argentina|\n",
      "|       south_korea|\n",
      "|           germany|\n",
      "|            russia|\n",
      "|             italy|\n",
      "|           ireland|\n",
      "|           belgium|\n",
      "|           romania|\n",
      "|            norway|\n",
      "|           denmark|\n",
      "|           bahamas|\n",
      "|       philippines|\n",
      "|             china|\n",
      "|          bulgaria|\n",
      "|      united_state|\n",
      "|           hungary|\n",
      "|             spain|\n",
      "|            mexico|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace \"USA\" with \"united_state\" in the production_country column\n",
    "df_dataset1_clean = df_dataset1_clean.withColumn(\"production_country\",\n",
    "                                                 when(df_dataset1_clean[\"production_country\"] == \"USA\", \"united_state\")\n",
    "                                                 .otherwise(df_dataset1_clean[\"production_country\"]))\n",
    "\n",
    "# Show unique values in the production_country column\n",
    "df_dataset1_clean.select(\"production_country\").distinct().show(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e39865",
   "metadata": {},
   "source": [
    "## get ouliners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "351228e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+------------------+\n",
      "|   budget|popularity|   revenue|runtime|vote_average|vote_count|          genre|release_date|production_country|           z_score|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+------------------+\n",
      "|300000000|139.082615| 961000000|    169|         6.9|      4500|         Action|  2007-05-19|      united_state| 4.883900050768747|\n",
      "|245000000|107.376788| 880674609|    148|         6.3|      4466|         Action|  2015-10-26|    united_kingdom|3.8168113523519165|\n",
      "|250000000| 112.31295|1084939099|    165|         7.6|      9106|         Action|  2012-07-16|      united_state|3.9138194158443556|\n",
      "|260000000| 43.926995| 284139100|    132|         6.1|      2124|         Action|  2012-03-07|      united_state| 4.107835542829234|\n",
      "|260000000| 48.681969| 591794936|    100|         7.4|      3330|      Animation|  2010-11-24|      united_state| 4.107835542829234|\n",
      "|280000000|134.279229|1405403694|    141|         7.3|      6767|         Action|  2015-04-22|      united_state| 4.495867796798991|\n",
      "|250000000| 98.885637| 933959197|    153|         7.4|      5293|      Advanture|  2009-07-07|    united_kingdom|3.9138194158443556|\n",
      "|250000000|155.790452| 873260194|    151|         5.7|      7004|         Action|  2016-03-23|      united_state|3.9138194158443556|\n",
      "|270000000| 57.925623| 391081192|    154|         5.4|      1400|         Action|  2006-06-28|      united_state| 4.301851669814112|\n",
      "|255000000| 49.046956|  89289910|    149|         5.9|      2311|         Action|  2013-07-03|      united_state| 4.010827479336795|\n",
      "|225000000| 99.398009| 662845518|    143|         6.5|      6359|         Action|  2013-06-12|    united_kingdom|3.4287790983821598|\n",
      "|225000000| 53.978602| 419651413|    150|         6.3|      1630|      Advanture|  2008-05-15|    czech republic|3.4287790983821598|\n",
      "|220000000|144.448633|1519557910|    143|         7.4|     11776|Science fiction|  2012-04-25|      united_state|3.3317710348897207|\n",
      "|380000000|135.413856|1045713802|    136|         6.4|      4948|      Advanture|  2011-05-14|      united_state| 6.436029066647774|\n",
      "|225000000| 52.035179| 624026776|    106|         6.2|      4160|         Action|  2012-05-23|      united_state|3.4287790983821598|\n",
      "|250000000|120.965743| 956019788|    144|         7.1|      4760|         Action|  2014-12-10|       new_zealand|3.9138194158443556|\n",
      "|215000000| 89.866276| 752215857|    136|         6.5|      6586|         Action|  2012-06-27|      united_state|3.2347629713972816|\n",
      "|250000000| 94.370564| 958400000|    161|         7.6|      4524|      Advanture|  2013-12-11|       new_zealand|3.9138194158443556|\n",
      "|207000000|  61.22601| 550000000|    187|         6.6|      2337|      Advanture|  2005-12-14|       new_zealand| 3.079550069809379|\n",
      "|250000000|198.372395|1153304495|    147|         7.1|      7241|      Advanture|  2016-04-27|      united_state|3.9138194158443556|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import stddev, mean\n",
    "\n",
    "# Calculate the mean and standard deviation of the column\n",
    "mean_val = df_dataset1_clean.select(mean(col(\"budget\"))).first()[0]\n",
    "stddev_val = df_dataset1_clean.select(stddev(col(\"budget\"))).first()[0]\n",
    "\n",
    "# Set the threshold for outliers (e.g., 3 standard deviations from the mean)\n",
    "threshold = 3\n",
    "\n",
    "# Calculate Z-score for each row\n",
    "df_dataset1_clean = df_dataset1_clean.withColumn(\"z_score\", (col(\"budget\") - mean_val) / stddev_val)\n",
    "\n",
    "# Filter rows with Z-score greater than the threshold (outliers)\n",
    "outliers = df_dataset1_clean.filter(col(\"z_score\") > threshold)\n",
    "\n",
    "outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "106871e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+------------------+\n",
      "|   budget|popularity|   revenue|runtime|vote_average|vote_count|          genre|release_date|production_country|           z_score|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+------------------+\n",
      "|300000000|139.082615| 961000000|    169|         6.9|      4500|         Action|  2007-05-19|      united_state| 3.996227966211781|\n",
      "|245000000|107.376788| 880674609|    148|         6.3|      4466|         Action|  2015-10-26|    united_kingdom|3.6052352129468197|\n",
      "|250000000| 112.31295|1084939099|    165|         7.6|      9106|         Action|  2012-07-16|      united_state| 4.599515282363017|\n",
      "|280000000|134.279229|1405403694|    141|         7.3|      6767|         Action|  2015-04-22|      united_state| 6.159412255948751|\n",
      "|250000000| 98.885637| 933959197|    153|         7.4|      5293|      Advanture|  2009-07-07|    united_kingdom| 3.864603857273856|\n",
      "|250000000|155.790452| 873260194|    151|         5.7|      7004|         Action|  2016-03-23|      united_state| 3.569144725261562|\n",
      "|200000000|145.847379|1065659812|    151|         7.0|      5246|      Advanture|  2006-06-20|           jamaica| 4.505671213740738|\n",
      "|220000000|144.448633|1519557910|    143|         7.4|     11776|Science fiction|  2012-04-25|      united_state| 6.715070568407424|\n",
      "|380000000|135.413856|1045713802|    136|         6.4|      4948|      Advanture|  2011-05-14|      united_state|4.4085817969391385|\n",
      "|250000000|120.965743| 956019788|    144|         7.1|      4760|         Action|  2014-12-10|       new_zealand| 3.971986231718099|\n",
      "|250000000| 94.370564| 958400000|    161|         7.6|      4524|      Advanture|  2013-12-11|       new_zealand|3.9835721777265576|\n",
      "|250000000|198.372395|1153304495|    147|         7.1|      7241|      Advanture|  2016-04-27|      united_state|4.9322914329340035|\n",
      "|150000000|418.708552|1513528810|    124|         6.5|      8662|         Action|  2015-06-09|      united_state| 6.685723255193477|\n",
      "|200000000| 93.004993|1108561013|    143|         6.9|      7604|         Action|  2012-10-25|    united_kingdom| 4.714497569747689|\n",
      "|200000000|  77.68208|1215439994|    130|         6.8|      8806|         Action|  2013-04-18|             china|  5.23474286861394|\n",
      "|200000000| 78.530105|1025491110|    108|         6.4|      4645|         others|  2010-03-03|      united_state| 4.310145599803051|\n",
      "|150000000| 21.939663| 836297228|    150|         6.0|      3138|Science fiction|  2009-06-19|      united_state|3.3892233869990545|\n",
      "|210000000|116.840296|1091405097|    165|         5.8|      3095|Science fiction|  2014-06-25|      united_state| 4.630989245068355|\n",
      "|200000000| 59.995418|1066969703|    103|         7.6|      4597|      Animation|  2010-06-16|      united_state| 4.512047253523314|\n",
      "|190000000|102.322217|1506249360|    137|         7.3|      4176|         Action|  2015-04-01|             japan| 6.650289724620876|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation of the column\n",
    "mean_val = df_dataset1_clean.select(mean(col(\"revenue\"))).first()[0]\n",
    "stddev_val = df_dataset1_clean.select(stddev(col(\"revenue\"))).first()[0]\n",
    "\n",
    "# Set the threshold for outliers (e.g., 3 standard deviations from the mean)\n",
    "threshold = 3\n",
    "\n",
    "# Calculate Z-score for each row\n",
    "df_dataset1_clean = df_dataset1_clean.withColumn(\"z_score\", (col(\"revenue\") - mean_val) / stddev_val)\n",
    "\n",
    "# Filter rows with Z-score greater than the threshold (outliers)\n",
    "outliers = df_dataset1_clean.filter(col(\"z_score\") > threshold)\n",
    "\n",
    "outliers.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "713a5bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+\n",
      "|   budget|popularity|   revenue|runtime|vote_average|vote_count|          genre|release_date|production_country|    profit|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+\n",
      "|300000000|139.082615| 961000000|    169|         6.9|      4500|         Action|  2007-05-19|      united_state| 661000000|\n",
      "|245000000|107.376788| 880674609|    148|         6.3|      4466|         Action|  2015-10-26|    united_kingdom| 635674609|\n",
      "|250000000| 112.31295|1084939099|    165|         7.6|      9106|         Action|  2012-07-16|      united_state| 834939099|\n",
      "|260000000| 43.926995| 284139100|    132|         6.1|      2124|         Action|  2012-03-07|      united_state|  24139100|\n",
      "|260000000| 48.681969| 591794936|    100|         7.4|      3330|      Animation|  2010-11-24|      united_state| 331794936|\n",
      "|280000000|134.279229|1405403694|    141|         7.3|      6767|         Action|  2015-04-22|      united_state|1125403694|\n",
      "|250000000| 98.885637| 933959197|    153|         7.4|      5293|      Advanture|  2009-07-07|    united_kingdom| 683959197|\n",
      "|250000000|155.790452| 873260194|    151|         5.7|      7004|         Action|  2016-03-23|      united_state| 623260194|\n",
      "|270000000| 57.925623| 391081192|    154|         5.4|      1400|         Action|  2006-06-28|      united_state| 121081192|\n",
      "|200000000|107.928811| 586090727|    106|         6.1|      2965|      Advanture|  2008-10-30|    united_kingdom| 386090727|\n",
      "|200000000|145.847379|1065659812|    151|         7.0|      5246|      Advanture|  2006-06-20|           jamaica| 865659812|\n",
      "|255000000| 49.046956|  89289910|    149|         5.9|      2311|         Action|  2013-07-03|      united_state|-165710090|\n",
      "|225000000| 99.398009| 662845518|    143|         6.5|      6359|         Action|  2013-06-12|    united_kingdom| 437845518|\n",
      "|225000000| 53.978602| 419651413|    150|         6.3|      1630|      Advanture|  2008-05-15|    czech republic| 194651413|\n",
      "|220000000|144.448633|1519557910|    143|         7.4|     11776|Science fiction|  2012-04-25|      united_state|1299557910|\n",
      "|380000000|135.413856|1045713802|    136|         6.4|      4948|      Advanture|  2011-05-14|      united_state| 665713802|\n",
      "|225000000| 52.035179| 624026776|    106|         6.2|      4160|         Action|  2012-05-23|      united_state| 399026776|\n",
      "|250000000|120.965743| 956019788|    144|         7.1|      4760|         Action|  2014-12-10|       new_zealand| 706019788|\n",
      "|215000000| 89.866276| 752215857|    136|         6.5|      6586|         Action|  2012-06-27|      united_state| 537215857|\n",
      "|200000000| 37.668301| 310669540|    140|         6.2|      1398|         Action|  2010-05-12|    united_kingdom| 110669540|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dataset1_clean = df_dataset1_clean.drop(\"z_score\")\n",
    "df_dataset1_clean.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e02372a",
   "metadata": {},
   "source": [
    "## create columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d9991037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+--------------------+----------+\n",
      "|   budget|popularity|   revenue|runtime|vote_average|vote_count|          genre|release_date|production_country|             z_score|    profit|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+--------------------+----------+\n",
      "|300000000|139.082615| 961000000|    169|         6.9|      4500|         Action|  2007-05-19|      united_state|   3.996227966211781| 661000000|\n",
      "|245000000|107.376788| 880674609|    148|         6.3|      4466|         Action|  2015-10-26|    united_kingdom|  3.6052352129468197| 635674609|\n",
      "|250000000| 112.31295|1084939099|    165|         7.6|      9106|         Action|  2012-07-16|      united_state|   4.599515282363017| 834939099|\n",
      "|260000000| 43.926995| 284139100|    132|         6.1|      2124|         Action|  2012-03-07|      united_state|  0.7015324337816972|  24139100|\n",
      "|260000000| 48.681969| 591794936|    100|         7.4|      3330|      Animation|  2010-11-24|      united_state|   2.199081351728121| 331794936|\n",
      "|280000000|134.279229|1405403694|    141|         7.3|      6767|         Action|  2015-04-22|      united_state|   6.159412255948751|1125403694|\n",
      "|250000000| 98.885637| 933959197|    153|         7.4|      5293|      Advanture|  2009-07-07|    united_kingdom|   3.864603857273856| 683959197|\n",
      "|250000000|155.790452| 873260194|    151|         5.7|      7004|         Action|  2016-03-23|      united_state|   3.569144725261562| 623260194|\n",
      "|270000000| 57.925623| 391081192|    154|         5.4|      1400|         Action|  2006-06-28|      united_state|  1.2220849324429834| 121081192|\n",
      "|200000000|107.928811| 586090727|    106|         6.1|      2965|      Advanture|  2008-10-30|    united_kingdom|  2.1713154815052325| 386090727|\n",
      "|200000000|145.847379|1065659812|    151|         7.0|      5246|      Advanture|  2006-06-20|           jamaica|   4.505671213740738| 865659812|\n",
      "|255000000| 49.046956|  89289910|    149|         5.9|      2311|         Action|  2013-07-03|      united_state|-0.24691761820183544|-165710090|\n",
      "|225000000| 99.398009| 662845518|    143|         6.5|      6359|         Action|  2013-06-12|    united_kingdom|   2.544927943091217| 437845518|\n",
      "|225000000| 53.978602| 419651413|    150|         6.3|      1630|      Advanture|  2008-05-15|    czech republic|  1.3611536531937907| 194651413|\n",
      "|220000000|144.448633|1519557910|    143|         7.4|     11776|Science fiction|  2012-04-25|      united_state|   6.715070568407424|1299557910|\n",
      "|380000000|135.413856|1045713802|    136|         6.4|      4948|      Advanture|  2011-05-14|      united_state|  4.4085817969391385| 665713802|\n",
      "|225000000| 52.035179| 624026776|    106|         6.2|      4160|         Action|  2012-05-23|      united_state|   2.355973409239496| 399026776|\n",
      "|250000000|120.965743| 956019788|    144|         7.1|      4760|         Action|  2014-12-10|       new_zealand|   3.971986231718099| 706019788|\n",
      "|215000000| 89.866276| 752215857|    136|         6.5|      6586|         Action|  2012-06-27|      united_state|    2.97994798433612| 537215857|\n",
      "|200000000| 37.668301| 310669540|    140|         6.2|      1398|         Action|  2010-05-12|    united_kingdom|  0.8306722941893591| 110669540|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'profit' to the DataFrame\n",
    "df_dataset1_clean = df_dataset1_clean.withColumn(\"profit\", col(\"revenue\") - col(\"budget\"))\n",
    "\n",
    "# Show the DataFrame\n",
    "df_dataset1_clean.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa8bf7b",
   "metadata": {},
   "source": [
    "## second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9e445b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset2 = spark.read.csv('data/IMDB Top 250 Movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8b1c581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------+------+------------------+-------------+-------------+\n",
      "|release_date|vote_average|    genre|  time|production_country|       budget|      revenue|\n",
      "+------------+------------+---------+------+------------------+-------------+-------------+\n",
      "|  16/10/2022|         8.3|   Action|2h 10m|               USA|    170000000|   1488732821|\n",
      "|  30/06/2021|         8.2|   Action|2h 28m|               USA|    200000000|   1921847111|\n",
      "|  24/06/2021|         8.8|    Crime|2h 44m|               USA|Not Available|Not Available|\n",
      "|  18/12/2020|         8.4|Biography|2h 40m|               USA|Not Available|Not Available|\n",
      "|  10/10/2020|         8.2|    Drama|1h 37m|               USA|      6000000|     24427162|\n",
      "|  04/10/2019|         8.5|    Drama|2h 12m|      south korean|     11400000|    262676096|\n",
      "|  15/03/2019|         8.4|    Crime| 2h 2m|               USA|     55000000|   1074458282|\n",
      "|  18/06/2019|         8.4|   Action| 3h 1m|               USA|    356000000|   2799439100|\n",
      "|  03/03/2019|         8.2|   Action|1h 59m|               USA|     95000000|    384479940|\n",
      "|  30/12/2019|         8.2|Animation|1h 36m|             spain|Not Available|Not Available|\n",
      "|  30/06/2019|         8.1|   Action|2h 32m|               USA|     97600000|    225508210|\n",
      "|  03/03/2018|         8.4|   Action|2h 29m|               USA|    321000000|   2052415039|\n",
      "|  06/06/2018|         8.4|Animation|1h 57m|               USA|Not Available|Not Available|\n",
      "|  28/04/2018|         8.4|    Drama| 2h 6m|               USA|Not Available|Not Available|\n",
      "|  13/01/2018|         8.2|Biography|2h 10m|               USA|     23000000|    321752656|\n",
      "|  13/01/2017|         8.4|Animation|1h 45m|               USA|    175000000|    814337054|\n",
      "|  15/09/2017|         8.1|   Comedy|1h 55m|               USA|     15000000|    162861289|\n",
      "|  06/12/2017|         8.1|   Action|2h 17m|               USA|     97000000|    619179950|\n",
      "|  22/10/2016|         8.4|Animation|1h 46m|             japan|Not Available|Not Available|\n",
      "|  05/05/2016|         8.3|   Action|2h 41m|               USA|Not Available|Not Available|\n",
      "+------------+------------+---------+------+------------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dataset2 = df_dataset2.withColumnRenamed(\"_c0\", \"rank\") \\\n",
    "       .withColumnRenamed(\"_c1\", \"title\") \\\n",
    "       .withColumnRenamed(\"_c2\", \"release_date\") \\\n",
    "       .withColumnRenamed(\"_c3\", \"vote_average\") \\\n",
    "       .withColumnRenamed(\"_c4\", \"genre\") \\\n",
    "       .withColumnRenamed(\"_c5\", \"certificate\") \\\n",
    "       .withColumnRenamed(\"_c6\", \"time\") \\\n",
    "       .withColumnRenamed(\"_c7\", \"production_country\") \\\n",
    "       .withColumnRenamed(\"_c8\", \"tagline\") \\\n",
    "       .withColumnRenamed(\"_c9\", \"budget\") \\\n",
    "       .withColumnRenamed(\"_c10\", \"revenue\") \\\n",
    "       .withColumnRenamed(\"_c11\", \"casts\") \\\n",
    "       .withColumnRenamed(\"_c12\", \"directors\")\\\n",
    "       .withColumnRenamed(\"_c13\", \"writers\")\n",
    "\n",
    "# Drop specified columns\n",
    "columns_to_drop = [\"rank\", \"title\", \"certificate\", \"tagline\", \"casts\", \"directors\", \"writers\",'_c14','_c15','_c16','_c17','_c18','_c19','_c20','_c21','_c22','_c23','_c24']\n",
    "df_dataset2_clean = df_dataset2.drop(*columns_to_drop)\n",
    "\n",
    "# Remove the first row\n",
    "df_dataset2_clean = df_dataset2_clean.filter(df_dataset2_clean[\"release_date\"] != \"year\")\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df_dataset2_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e3d37832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------+------+------------------+---------+----------+-------+\n",
      "|release_date|vote_average|    genre|  time|production_country|   budget|   revenue|runtime|\n",
      "+------------+------------+---------+------+------------------+---------+----------+-------+\n",
      "|  2022-10-16|         8.3|   Action|2h 10m|               USA|170000000|1488732821|    130|\n",
      "|  2021-06-30|         8.2|   Action|2h 28m|               USA|200000000|1921847111|    148|\n",
      "|  2021-06-24|         8.8|    Crime|2h 44m|               USA|     null|      null|    164|\n",
      "|  2020-12-18|         8.4|Biography|2h 40m|               USA|     null|      null|    160|\n",
      "|  2020-10-10|         8.2|    Drama|1h 37m|               USA|  6000000|  24427162|     97|\n",
      "|  2019-10-04|         8.5|    Drama|2h 12m|      south korean| 11400000| 262676096|    132|\n",
      "|  2019-03-15|         8.4|    Crime| 2h 2m|               USA| 55000000|1074458282|    122|\n",
      "|  2019-06-18|         8.4|   Action| 3h 1m|               USA|356000000|      null|    181|\n",
      "|  2019-03-03|         8.2|   Action|1h 59m|               USA| 95000000| 384479940|    119|\n",
      "|  2019-12-30|         8.2|Animation|1h 36m|             spain|     null|      null|     96|\n",
      "|  2019-06-30|         8.1|   Action|2h 32m|               USA| 97600000| 225508210|    152|\n",
      "|  2018-03-03|         8.4|   Action|2h 29m|               USA|321000000|2052415039|    149|\n",
      "|  2018-06-06|         8.4|Animation|1h 57m|               USA|     null|      null|    117|\n",
      "|  2018-04-28|         8.4|    Drama| 2h 6m|               USA|     null|      null|    126|\n",
      "|  2018-01-13|         8.2|Biography|2h 10m|               USA| 23000000| 321752656|    130|\n",
      "|  2017-01-13|         8.4|Animation|1h 45m|               USA|175000000| 814337054|    105|\n",
      "|  2017-09-15|         8.1|   Comedy|1h 55m|               USA| 15000000| 162861289|    115|\n",
      "|  2017-12-06|         8.1|   Action|2h 17m|               USA| 97000000| 619179950|    137|\n",
      "|  2016-10-22|         8.4|Animation|1h 46m|             japan|     null|      null|    106|\n",
      "|  2016-05-05|         8.3|   Action|2h 41m|               USA|     null|      null|    161|\n",
      "+------------+------------+---------+------+------------------+---------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "# Convert columns to the desired data types\n",
    "df_dataset2_clean = df_dataset2_clean.withColumn(\"budget\", df_dataset2_clean[\"budget\"].cast(IntegerType()))\n",
    "df_dataset2_clean = df_dataset2_clean.withColumn(\"revenue\", df_dataset2_clean[\"revenue\"].cast(IntegerType()))\n",
    "\n",
    "# Extract numerical values from the \"runtime\" column\n",
    "# Extract hours and minutes separately\n",
    "hours = regexp_extract(df_dataset2_clean[\"time\"], r\"(\\d+)h\", 1)\n",
    "minutes = regexp_extract(df_dataset2_clean[\"time\"], r\"(\\d+)m\", 1)\n",
    "\n",
    "# Convert hours and minutes to minutes and sum them up\n",
    "total_minutes = hours * 60 + minutes\n",
    "\n",
    "# Add a new column with the total runtime in minutes\n",
    "df_dataset2_clean = df_dataset2_clean.withColumn(\"runtime\", total_minutes)\n",
    "\n",
    "# Convert the extracted values to integers\n",
    "df_dataset2_clean = df_dataset2_clean.withColumn(\"runtime\", df_dataset2_clean[\"runtime\"].cast(IntegerType()))\n",
    "\n",
    "df_dataset2_clean = df_dataset2_clean.withColumn(\"vote_average\", df_dataset2_clean[\"vote_average\"].cast(DoubleType()))\n",
    "df_dataset2_clean = df_dataset2_clean.withColumn(\"release_date\", to_date(df_dataset2_clean[\"release_date\"], \"dd/MM/yyyy\"))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_dataset2_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b327b9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------+------------------+---------+----------+-------+\n",
      "|release_date|vote_average|    genre|production_country|   budget|   revenue|runtime|\n",
      "+------------+------------+---------+------------------+---------+----------+-------+\n",
      "|  2022-10-16|         8.3|   Action|               USA|170000000|1488732821|    130|\n",
      "|  2021-06-30|         8.2|   Action|               USA|200000000|1921847111|    148|\n",
      "|  2021-06-24|         8.8|    Crime|               USA|     null|      null|    164|\n",
      "|  2020-12-18|         8.4|Biography|               USA|     null|      null|    160|\n",
      "|  2020-10-10|         8.2|    Drama|               USA|  6000000|  24427162|     97|\n",
      "|  2019-10-04|         8.5|    Drama|      south korean| 11400000| 262676096|    132|\n",
      "|  2019-03-15|         8.4|    Crime|               USA| 55000000|1074458282|    122|\n",
      "|  2019-06-18|         8.4|   Action|               USA|356000000|      null|    181|\n",
      "|  2019-03-03|         8.2|   Action|               USA| 95000000| 384479940|    119|\n",
      "|  2019-12-30|         8.2|Animation|             spain|     null|      null|     96|\n",
      "|  2019-06-30|         8.1|   Action|               USA| 97600000| 225508210|    152|\n",
      "|  2018-03-03|         8.4|   Action|               USA|321000000|2052415039|    149|\n",
      "|  2018-06-06|         8.4|Animation|               USA|     null|      null|    117|\n",
      "|  2018-04-28|         8.4|    Drama|               USA|     null|      null|    126|\n",
      "|  2018-01-13|         8.2|Biography|               USA| 23000000| 321752656|    130|\n",
      "|  2017-01-13|         8.4|Animation|               USA|175000000| 814337054|    105|\n",
      "|  2017-09-15|         8.1|   Comedy|               USA| 15000000| 162861289|    115|\n",
      "|  2017-12-06|         8.1|   Action|               USA| 97000000| 619179950|    137|\n",
      "|  2016-10-22|         8.4|Animation|             japan|     null|      null|    106|\n",
      "|  2016-05-05|         8.3|   Action|               USA|     null|      null|    161|\n",
      "+------------+------------+---------+------------------+---------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# Filter rows based on the \"release_date\" column\n",
    "df_dataset2_clean = df_dataset2_clean = df_dataset2_clean.filter(col(\"release_date\") > '2015-01-01')\n",
    "\n",
    "# drop time\n",
    "df_dataset2_clean = df_dataset2_clean.drop(\"time\")\n",
    "\n",
    "df_dataset2_clean.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a2fca8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------+------------------+---------+----------+-------+\n",
      "|release_date|vote_average|    genre|production_country|   budget|   revenue|runtime|\n",
      "+------------+------------+---------+------------------+---------+----------+-------+\n",
      "|  2022-10-16|         8.3|   Action|               USA|170000000|1488732821|    130|\n",
      "|  2021-06-30|         8.2|   Action|               USA|200000000|1921847111|    148|\n",
      "|  2020-10-10|         8.2|    Drama|               USA|  6000000|  24427162|     97|\n",
      "|  2019-10-04|         8.5|    Drama|      south korean| 11400000| 262676096|    132|\n",
      "|  2019-03-15|         8.4|    Crime|               USA| 55000000|1074458282|    122|\n",
      "|  2019-03-03|         8.2|   Action|               USA| 95000000| 384479940|    119|\n",
      "|  2019-06-30|         8.1|   Action|               USA| 97600000| 225508210|    152|\n",
      "|  2018-03-03|         8.4|   Action|               USA|321000000|2052415039|    149|\n",
      "|  2018-01-13|         8.2|Biography|               USA| 23000000| 321752656|    130|\n",
      "|  2017-01-13|         8.4|Animation|               USA|175000000| 814337054|    105|\n",
      "|  2017-09-15|         8.1|   Comedy|               USA| 15000000| 162861289|    115|\n",
      "|  2017-12-06|         8.1|   Action|               USA| 97000000| 619179950|    137|\n",
      "|  2016-12-12|         8.1|Biography|               USA| 40000000| 180563636|    139|\n",
      "|  2015-05-11|         8.2|Animation|               USA|175000000| 858848019|     95|\n",
      "|  2015-10-22|         8.1|    Drama|               USA| 13000000|  35401758|    118|\n",
      "|  2015-10-04|         8.1|Biography|               USA| 20000000|  98690254|    129|\n",
      "+------------+------------+---------+------------------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop null\n",
    "# Drop rows with null values in any column\n",
    "df_dataset2_clean = df_dataset2_clean.dropna()\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_dataset2_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "85f61bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------+------------------+---------+----------+-------+\n",
      "|release_date|vote_average|    genre|production_country|   budget|   revenue|runtime|\n",
      "+------------+------------+---------+------------------+---------+----------+-------+\n",
      "|  2022-10-16|         8.3|   Action|      united_state|170000000|1488732821|    130|\n",
      "|  2021-06-30|         8.2|   Action|      united_state|200000000|1921847111|    148|\n",
      "|  2020-10-10|         8.2|    Drama|      united_state|  6000000|  24427162|     97|\n",
      "|  2019-10-04|         8.5|    Drama|      south korean| 11400000| 262676096|    132|\n",
      "|  2019-03-15|         8.4|    Crime|      united_state| 55000000|1074458282|    122|\n",
      "|  2019-03-03|         8.2|   Action|      united_state| 95000000| 384479940|    119|\n",
      "|  2019-06-30|         8.1|   Action|      united_state| 97600000| 225508210|    152|\n",
      "|  2018-03-03|         8.4|   Action|      united_state|321000000|2052415039|    149|\n",
      "|  2018-01-13|         8.2|Biography|      united_state| 23000000| 321752656|    130|\n",
      "|  2017-01-13|         8.4|Animation|      united_state|175000000| 814337054|    105|\n",
      "|  2017-09-15|         8.1|   Comedy|      united_state| 15000000| 162861289|    115|\n",
      "|  2017-12-06|         8.1|   Action|      united_state| 97000000| 619179950|    137|\n",
      "|  2016-12-12|         8.1|Biography|      united_state| 40000000| 180563636|    139|\n",
      "|  2015-05-11|         8.2|Animation|      united_state|175000000| 858848019|     95|\n",
      "|  2015-10-22|         8.1|    Drama|      united_state| 13000000|  35401758|    118|\n",
      "|  2015-10-04|         8.1|Biography|      united_state| 20000000|  98690254|    129|\n",
      "+------------+------------+---------+------------------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace \"USA\" with \"united_state\" in the production_country column\n",
    "df_dataset2_clean = df_dataset2_clean.withColumn(\"production_country\", \\\n",
    "            when(df_dataset2_clean[\"production_country\"] == \"USA\", \"united_state\") \\\n",
    "            .otherwise(df_dataset2_clean[\"production_country\"]))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_dataset2_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5ee71410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------+------------------+---------+----------+-------+----------+\n",
      "|release_date|vote_average|    genre|production_country|   budget|   revenue|runtime|    profit|\n",
      "+------------+------------+---------+------------------+---------+----------+-------+----------+\n",
      "|  2022-10-16|         8.3|   Action|      united_state|170000000|1488732821|    130|1318732821|\n",
      "|  2021-06-30|         8.2|   Action|      united_state|200000000|1921847111|    148|1721847111|\n",
      "|  2020-10-10|         8.2|    Drama|      united_state|  6000000|  24427162|     97|  18427162|\n",
      "|  2019-10-04|         8.5|    Drama|      south korean| 11400000| 262676096|    132| 251276096|\n",
      "|  2019-03-15|         8.4|    Crime|      united_state| 55000000|1074458282|    122|1019458282|\n",
      "|  2019-03-03|         8.2|   Action|      united_state| 95000000| 384479940|    119| 289479940|\n",
      "|  2019-06-30|         8.1|   Action|      united_state| 97600000| 225508210|    152| 127908210|\n",
      "|  2018-03-03|         8.4|   Action|      united_state|321000000|2052415039|    149|1731415039|\n",
      "|  2018-01-13|         8.2|Biography|      united_state| 23000000| 321752656|    130| 298752656|\n",
      "|  2017-01-13|         8.4|Animation|      united_state|175000000| 814337054|    105| 639337054|\n",
      "|  2017-09-15|         8.1|   Comedy|      united_state| 15000000| 162861289|    115| 147861289|\n",
      "|  2017-12-06|         8.1|   Action|      united_state| 97000000| 619179950|    137| 522179950|\n",
      "|  2016-12-12|         8.1|Biography|      united_state| 40000000| 180563636|    139| 140563636|\n",
      "|  2015-05-11|         8.2|Animation|      united_state|175000000| 858848019|     95| 683848019|\n",
      "|  2015-10-22|         8.1|    Drama|      united_state| 13000000|  35401758|    118|  22401758|\n",
      "|  2015-10-04|         8.1|Biography|      united_state| 20000000|  98690254|    129|  78690254|\n",
      "+------------+------------+---------+------------------+---------+----------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'profit' based on 'revenue' and 'budget'\n",
    "df_dataset2_clean = df_dataset2_clean.withColumn(\"profit\", col(\"revenue\") - col(\"budget\"))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_dataset2_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "72a9ab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- revenue: integer (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- vote_average: double (nullable = true)\n",
      " |-- vote_count: integer (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- release_date: date (nullable = true)\n",
      " |-- production_country: string (nullable = true)\n",
      " |-- profit: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- release_date: date (nullable = true)\n",
      " |-- vote_average: double (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- production_country: string (nullable = true)\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- revenue: integer (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- profit: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dataset1_clean.printSchema()\n",
    "df_dataset2_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cca90f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------+------------------+---------+----------+-------+----------+----------+----------+\n",
      "|release_date|vote_average|    genre|production_country|   budget|   revenue|runtime|    profit|popularity|vote_count|\n",
      "+------------+------------+---------+------------------+---------+----------+-------+----------+----------+----------+\n",
      "|  2022-10-16|         8.3|   Action|      united_state|170000000|1488732821|    130|1318732821|      null|      null|\n",
      "|  2021-06-30|         8.2|   Action|      united_state|200000000|1921847111|    148|1721847111|      null|      null|\n",
      "|  2020-10-10|         8.2|    Drama|      united_state|  6000000|  24427162|     97|  18427162|      null|      null|\n",
      "|  2019-10-04|         8.5|    Drama|      south korean| 11400000| 262676096|    132| 251276096|      null|      null|\n",
      "|  2019-03-15|         8.4|    Crime|      united_state| 55000000|1074458282|    122|1019458282|      null|      null|\n",
      "|  2019-03-03|         8.2|   Action|      united_state| 95000000| 384479940|    119| 289479940|      null|      null|\n",
      "|  2019-06-30|         8.1|   Action|      united_state| 97600000| 225508210|    152| 127908210|      null|      null|\n",
      "|  2018-03-03|         8.4|   Action|      united_state|321000000|2052415039|    149|1731415039|      null|      null|\n",
      "|  2018-01-13|         8.2|Biography|      united_state| 23000000| 321752656|    130| 298752656|      null|      null|\n",
      "|  2017-01-13|         8.4|Animation|      united_state|175000000| 814337054|    105| 639337054|      null|      null|\n",
      "|  2017-09-15|         8.1|   Comedy|      united_state| 15000000| 162861289|    115| 147861289|      null|      null|\n",
      "|  2017-12-06|         8.1|   Action|      united_state| 97000000| 619179950|    137| 522179950|      null|      null|\n",
      "|  2016-12-12|         8.1|Biography|      united_state| 40000000| 180563636|    139| 140563636|      null|      null|\n",
      "|  2015-05-11|         8.2|Animation|      united_state|175000000| 858848019|     95| 683848019|      null|      null|\n",
      "|  2015-10-22|         8.1|    Drama|      united_state| 13000000|  35401758|    118|  22401758|      null|      null|\n",
      "|  2015-10-04|         8.1|Biography|      united_state| 20000000|  98690254|    129|  78690254|      null|      null|\n",
      "+------------+------------+---------+------------------+---------+----------+-------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Define the missing columns and their default values\n",
    "missing_columns = [\"popularity\", \"vote_count\"]\n",
    "\n",
    "# Add each missing column with default values to df_dataset2_clean\n",
    "for column in missing_columns:\n",
    "    df_dataset2_clean = df_dataset2_clean.withColumn(column, lit(None).cast(df_dataset1_clean.schema[column].dataType))\n",
    "\n",
    "# Show the DataFrame with added columns\n",
    "df_dataset2_clean.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "99473886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+-------+------------+----------+---------+------------+------------------+----------+\n",
      "|   budget|popularity|   revenue|runtime|vote_average|vote_count|    genre|release_date|production_country|    profit|\n",
      "+---------+----------+----------+-------+------------+----------+---------+------------+------------------+----------+\n",
      "|170000000|      null|1488732821|    130|         8.3|      null|   Action|  2022-10-16|      united_state|1318732821|\n",
      "|200000000|      null|1921847111|    148|         8.2|      null|   Action|  2021-06-30|      united_state|1721847111|\n",
      "|  6000000|      null|  24427162|     97|         8.2|      null|    Drama|  2020-10-10|      united_state|  18427162|\n",
      "| 11400000|      null| 262676096|    132|         8.5|      null|    Drama|  2019-10-04|      south korean| 251276096|\n",
      "| 55000000|      null|1074458282|    122|         8.4|      null|    Crime|  2019-03-15|      united_state|1019458282|\n",
      "| 95000000|      null| 384479940|    119|         8.2|      null|   Action|  2019-03-03|      united_state| 289479940|\n",
      "| 97600000|      null| 225508210|    152|         8.1|      null|   Action|  2019-06-30|      united_state| 127908210|\n",
      "|321000000|      null|2052415039|    149|         8.4|      null|   Action|  2018-03-03|      united_state|1731415039|\n",
      "| 23000000|      null| 321752656|    130|         8.2|      null|Biography|  2018-01-13|      united_state| 298752656|\n",
      "|175000000|      null| 814337054|    105|         8.4|      null|Animation|  2017-01-13|      united_state| 639337054|\n",
      "| 15000000|      null| 162861289|    115|         8.1|      null|   Comedy|  2017-09-15|      united_state| 147861289|\n",
      "| 97000000|      null| 619179950|    137|         8.1|      null|   Action|  2017-12-06|      united_state| 522179950|\n",
      "| 40000000|      null| 180563636|    139|         8.1|      null|Biography|  2016-12-12|      united_state| 140563636|\n",
      "|175000000|      null| 858848019|     95|         8.2|      null|Animation|  2015-05-11|      united_state| 683848019|\n",
      "| 13000000|      null|  35401758|    118|         8.1|      null|    Drama|  2015-10-22|      united_state|  22401758|\n",
      "| 20000000|      null|  98690254|    129|         8.1|      null|Biography|  2015-10-04|      united_state|  78690254|\n",
      "+---------+----------+----------+-------+------------+----------+---------+------------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the column sequence from df_dataset1_clean\n",
    "column_sequence = [\"budget\", \"popularity\", \"revenue\", \"runtime\", \"vote_average\", \"vote_count\", \"genre\", \"release_date\", \"production_country\", \"profit\"]\n",
    "\n",
    "# Select columns in df_dataset2_clean in the order defined by column_sequence\n",
    "df_dataset2_clean = df_dataset2_clean.select(*column_sequence)\n",
    "\n",
    "# Show the DataFrame with swapped column sequences\n",
    "df_dataset2_clean.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c45208b",
   "metadata": {},
   "source": [
    "### Merge two dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f3f08b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+\n",
      "|   budget|popularity|   revenue|runtime|vote_average|vote_count|          genre|release_date|production_country|    profit|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+\n",
      "|300000000|139.082615| 961000000|    169|         6.9|      4500|         Action|  2007-05-19|      united_state| 661000000|\n",
      "|245000000|107.376788| 880674609|    148|         6.3|      4466|         Action|  2015-10-26|    united_kingdom| 635674609|\n",
      "|250000000| 112.31295|1084939099|    165|         7.6|      9106|         Action|  2012-07-16|      united_state| 834939099|\n",
      "|260000000| 43.926995| 284139100|    132|         6.1|      2124|         Action|  2012-03-07|      united_state|  24139100|\n",
      "|260000000| 48.681969| 591794936|    100|         7.4|      3330|      Animation|  2010-11-24|      united_state| 331794936|\n",
      "|280000000|134.279229|1405403694|    141|         7.3|      6767|         Action|  2015-04-22|      united_state|1125403694|\n",
      "|250000000| 98.885637| 933959197|    153|         7.4|      5293|      Advanture|  2009-07-07|    united_kingdom| 683959197|\n",
      "|250000000|155.790452| 873260194|    151|         5.7|      7004|         Action|  2016-03-23|      united_state| 623260194|\n",
      "|270000000| 57.925623| 391081192|    154|         5.4|      1400|         Action|  2006-06-28|      united_state| 121081192|\n",
      "|200000000|107.928811| 586090727|    106|         6.1|      2965|      Advanture|  2008-10-30|    united_kingdom| 386090727|\n",
      "|200000000|145.847379|1065659812|    151|         7.0|      5246|      Advanture|  2006-06-20|           jamaica| 865659812|\n",
      "|255000000| 49.046956|  89289910|    149|         5.9|      2311|         Action|  2013-07-03|      united_state|-165710090|\n",
      "|225000000| 99.398009| 662845518|    143|         6.5|      6359|         Action|  2013-06-12|    united_kingdom| 437845518|\n",
      "|225000000| 53.978602| 419651413|    150|         6.3|      1630|      Advanture|  2008-05-15|    czech republic| 194651413|\n",
      "|220000000|144.448633|1519557910|    143|         7.4|     11776|Science fiction|  2012-04-25|      united_state|1299557910|\n",
      "|380000000|135.413856|1045713802|    136|         6.4|      4948|      Advanture|  2011-05-14|      united_state| 665713802|\n",
      "|225000000| 52.035179| 624026776|    106|         6.2|      4160|         Action|  2012-05-23|      united_state| 399026776|\n",
      "|250000000|120.965743| 956019788|    144|         7.1|      4760|         Action|  2014-12-10|       new_zealand| 706019788|\n",
      "|215000000| 89.866276| 752215857|    136|         6.5|      6586|         Action|  2012-06-27|      united_state| 537215857|\n",
      "|200000000| 37.668301| 310669540|    140|         6.2|      1398|         Action|  2010-05-12|    united_kingdom| 110669540|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Union the DataFrames\n",
    "concatenated_df = df_dataset1_clean.union(df_dataset2_clean)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "concatenated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d20ade04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for column 'budget':\n",
      "+-------+-------------------+\n",
      "|summary|             budget|\n",
      "+-------+-------------------+\n",
      "|  count|               1665|\n",
      "|   mean|4.871892023723724E7|\n",
      "| stddev|5.221135091224088E7|\n",
      "|    min|              65000|\n",
      "|    max|          380000000|\n",
      "+-------+-------------------+\n",
      "\n",
      "Statistics for column 'popularity':\n",
      "+-------+-----------------+\n",
      "|summary|       popularity|\n",
      "+-------+-----------------+\n",
      "|  count|             1649|\n",
      "|   mean|34.66885861613099|\n",
      "| stddev|44.62214029434688|\n",
      "|    min|         0.041651|\n",
      "|    max|       875.581305|\n",
      "+-------+-----------------+\n",
      "\n",
      "Statistics for column 'revenue':\n",
      "+-------+--------------------+\n",
      "|summary|             revenue|\n",
      "+-------+--------------------+\n",
      "|  count|                1665|\n",
      "|   mean|1.4499308936936936E8|\n",
      "| stddev| 2.197874552841609E8|\n",
      "|    min|               53086|\n",
      "|    max|          2052415039|\n",
      "+-------+--------------------+\n",
      "\n",
      "Statistics for column 'runtime':\n",
      "+-------+------------------+\n",
      "|summary|           runtime|\n",
      "+-------+------------------+\n",
      "|  count|              1665|\n",
      "|   mean| 109.3057057057057|\n",
      "| stddev|18.657035494284017|\n",
      "|    min|                41|\n",
      "|    max|               338|\n",
      "+-------+------------------+\n",
      "\n",
      "Statistics for column 'vote_average':\n",
      "+-------+------------------+\n",
      "|summary|      vote_average|\n",
      "+-------+------------------+\n",
      "|  count|              1665|\n",
      "|   mean| 6.260120120120109|\n",
      "| stddev|0.8160617111050585|\n",
      "|    min|               2.3|\n",
      "|    max|               8.5|\n",
      "+-------+------------------+\n",
      "\n",
      "Statistics for column 'vote_count':\n",
      "+-------+------------------+\n",
      "|summary|        vote_count|\n",
      "+-------+------------------+\n",
      "|  count|              1649|\n",
      "|   mean|1201.3535476046088|\n",
      "| stddev|1576.3702524677194|\n",
      "|    min|                 1|\n",
      "|    max|             13752|\n",
      "+-------+------------------+\n",
      "\n",
      "Statistics for column 'genre':\n",
      "+-------+------+\n",
      "|summary| genre|\n",
      "+-------+------+\n",
      "|  count|  1665|\n",
      "|   mean|  null|\n",
      "| stddev|  null|\n",
      "|    min|Action|\n",
      "|    max|others|\n",
      "+-------+------+\n",
      "\n",
      "Statistics for column 'release_date':\n",
      "+-------+\n",
      "|summary|\n",
      "+-------+\n",
      "|  count|\n",
      "|   mean|\n",
      "| stddev|\n",
      "|    min|\n",
      "|    max|\n",
      "+-------+\n",
      "\n",
      "Statistics for column 'production_country':\n",
      "+-------+------------------+\n",
      "|summary|production_country|\n",
      "+-------+------------------+\n",
      "|  count|              1665|\n",
      "|   mean|              null|\n",
      "| stddev|              null|\n",
      "|    min|         australia|\n",
      "|    max|      united_state|\n",
      "+-------+------------------+\n",
      "\n",
      "Statistics for column 'profit':\n",
      "+-------+--------------------+\n",
      "|summary|              profit|\n",
      "+-------+--------------------+\n",
      "|  count|                1665|\n",
      "|   mean| 9.627416913213213E7|\n",
      "| stddev|1.8280246719200432E8|\n",
      "|    min|          -165710090|\n",
      "|    max|          1731415039|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the list of column names\n",
    "columns = concatenated_df.columns\n",
    "\n",
    "# Iterate over each column\n",
    "for column in columns:\n",
    "    print(f\"Statistics for column '{column}':\")\n",
    "    \n",
    "    # Calculate and display statistics for the current column\n",
    "    concatenated_df.describe(column).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cc7d941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in column 'budget': 0\n",
      "Number of null values in column 'popularity': 16\n",
      "Number of null values in column 'revenue': 0\n",
      "Number of null values in column 'runtime': 0\n",
      "Number of null values in column 'vote_average': 0\n",
      "Number of null values in column 'vote_count': 16\n",
      "Number of null values in column 'genre': 0\n",
      "Number of null values in column 'release_date': 0\n",
      "Number of null values in column 'production_country': 0\n",
      "Number of null values in column 'profit': 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Check for null values in each column\n",
    "for col_name in concatenated_df.columns:\n",
    "    null_count = concatenated_df.where(col(col_name).isNull()).count()\n",
    "    print(f\"Number of null values in column '{col_name}': {null_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "aef2c24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in column 'budget': 0\n",
      "Number of null values in column 'popularity': 0\n",
      "Number of null values in column 'revenue': 0\n",
      "Number of null values in column 'runtime': 0\n",
      "Number of null values in column 'vote_average': 0\n",
      "Number of null values in column 'vote_count': 0\n",
      "Number of null values in column 'genre': 0\n",
      "Number of null values in column 'release_date': 0\n",
      "Number of null values in column 'production_country': 0\n",
      "Number of null values in column 'profit': 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "\n",
    "# Fill null values with a random value sampled from the column distribution\n",
    "df_data = concatenated_df.withColumn(\"popularity\", when(concatenated_df[\"popularity\"].isNull(), rand()).otherwise(concatenated_df[\"popularity\"]))\n",
    "df_data = df_data.withColumn(\"vote_count\", when(concatenated_df[\"vote_count\"].isNull(), rand()).otherwise(concatenated_df[\"vote_count\"]))\n",
    "\n",
    "\n",
    "# Check again for null values\n",
    "for col_name in df_data.columns:\n",
    "    null_count = df_data.where(col(col_name).isNull()).count()\n",
    "    print(f\"Number of null values in column '{col_name}': {null_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6237cf21",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column popularity_rank already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [160]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m quantile_discretizer \u001b[38;5;241m=\u001b[39m Bucketizer(splits\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)], inputCol\u001b[38;5;241m=\u001b[39minput_col, outputCol\u001b[38;5;241m=\u001b[39minput_col\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_rank\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Apply discretization to the DataFrame\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m df_data_discretized \u001b[38;5;241m=\u001b[39m \u001b[43mquantile_discretizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Assign the discretized column back to the original DataFrame\u001b[39;00m\n\u001b[1;32m     17\u001b[0m df_data \u001b[38;5;241m=\u001b[39m df_data_discretized\u001b[38;5;241m.\u001b[39mwithColumnRenamed(input_col\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_rank\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopularity_rank\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/base.py:217\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py:350\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m, dataset\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Column popularity_rank already exists."
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Define the number of bins\n",
    "num_bins = 2\n",
    "\n",
    "# Define the column to be discretized\n",
    "input_col = 'popularity'\n",
    "\n",
    "# Quantile-based discretization strategy\n",
    "quantile_discretizer = Bucketizer(splits=[float(\"-inf\"), 0.5, float(\"inf\")], inputCol=input_col, outputCol=input_col+'_rank')\n",
    "\n",
    "# Apply discretization to the DataFrame\n",
    "df_data_discretized = quantile_discretizer.transform(df_data)\n",
    "\n",
    "# Assign the discretized column back to the original DataFrame\n",
    "df_data = df_data_discretized.withColumnRenamed(input_col+'_rank', 'popularity_rank')\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3e5221ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+---------------+\n",
      "|   budget|popularity|   revenue|runtime|vote_average|vote_count|          genre|release_date|production_country|    profit|popularity_rank|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+---------------+\n",
      "|300000000|139.082615| 961000000|    169|         6.9|    4500.0|         Action|  2007-05-19|      united_state| 661000000|            1.0|\n",
      "|245000000|107.376788| 880674609|    148|         6.3|    4466.0|         Action|  2015-10-26|    united_kingdom| 635674609|            1.0|\n",
      "|250000000| 112.31295|1084939099|    165|         7.6|    9106.0|         Action|  2012-07-16|      united_state| 834939099|            1.0|\n",
      "|260000000| 43.926995| 284139100|    132|         6.1|    2124.0|         Action|  2012-03-07|      united_state|  24139100|            1.0|\n",
      "|260000000| 48.681969| 591794936|    100|         7.4|    3330.0|      Animation|  2010-11-24|      united_state| 331794936|            1.0|\n",
      "|280000000|134.279229|1405403694|    141|         7.3|    6767.0|         Action|  2015-04-22|      united_state|1125403694|            1.0|\n",
      "|250000000| 98.885637| 933959197|    153|         7.4|    5293.0|      Advanture|  2009-07-07|    united_kingdom| 683959197|            1.0|\n",
      "|250000000|155.790452| 873260194|    151|         5.7|    7004.0|         Action|  2016-03-23|      united_state| 623260194|            1.0|\n",
      "|270000000| 57.925623| 391081192|    154|         5.4|    1400.0|         Action|  2006-06-28|      united_state| 121081192|            1.0|\n",
      "|200000000|107.928811| 586090727|    106|         6.1|    2965.0|      Advanture|  2008-10-30|    united_kingdom| 386090727|            1.0|\n",
      "|200000000|145.847379|1065659812|    151|         7.0|    5246.0|      Advanture|  2006-06-20|           jamaica| 865659812|            1.0|\n",
      "|255000000| 49.046956|  89289910|    149|         5.9|    2311.0|         Action|  2013-07-03|      united_state|-165710090|            1.0|\n",
      "|225000000| 99.398009| 662845518|    143|         6.5|    6359.0|         Action|  2013-06-12|    united_kingdom| 437845518|            1.0|\n",
      "|225000000| 53.978602| 419651413|    150|         6.3|    1630.0|      Advanture|  2008-05-15|    czech republic| 194651413|            1.0|\n",
      "|220000000|144.448633|1519557910|    143|         7.4|   11776.0|Science fiction|  2012-04-25|      united_state|1299557910|            1.0|\n",
      "|380000000|135.413856|1045713802|    136|         6.4|    4948.0|      Advanture|  2011-05-14|      united_state| 665713802|            1.0|\n",
      "|225000000| 52.035179| 624026776|    106|         6.2|    4160.0|         Action|  2012-05-23|      united_state| 399026776|            1.0|\n",
      "|250000000|120.965743| 956019788|    144|         7.1|    4760.0|         Action|  2014-12-10|       new_zealand| 706019788|            1.0|\n",
      "|215000000| 89.866276| 752215857|    136|         6.5|    6586.0|         Action|  2012-06-27|      united_state| 537215857|            1.0|\n",
      "|200000000| 37.668301| 310669540|    140|         6.2|    1398.0|         Action|  2010-05-12|    united_kingdom| 110669540|            1.0|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9ee1fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of bins\n",
    "num_bins = 3\n",
    "\n",
    "# Define the column to be discretized\n",
    "input_col = 'profit'\n",
    "\n",
    "# Quantile-based discretization strategy\n",
    "quantile_discretizer = Bucketizer(splits=[float(\"-inf\"), 0.333, 0.666, float(\"inf\")], inputCol=input_col, outputCol=input_col+'_bucket')\n",
    "\n",
    "# Apply discretization to the DataFrame\n",
    "df_data_discretized = quantile_discretizer.transform(df_data)\n",
    "\n",
    "# Reverse the order of the bins\n",
    "df_data_discretized = df_data_discretized.withColumn(input_col+'_bucket', (num_bins - 1 - col(input_col+'_bucket')).cast('integer'))\n",
    "\n",
    "# Assign the discretized column back to the original DataFrame\n",
    "df_data = df_data_discretized.withColumnRenamed(input_col+'_bucket', 'risk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "09c6324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+---------------+----+\n",
      "|   budget|popularity|   revenue|runtime|vote_average|vote_count|          genre|release_date|production_country|    profit|popularity_rank|risk|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+---------------+----+\n",
      "|300000000|139.082615| 961000000|    169|         6.9|    4500.0|         Action|  2007-05-19|      united_state| 661000000|            1.0|   0|\n",
      "|245000000|107.376788| 880674609|    148|         6.3|    4466.0|         Action|  2015-10-26|    united_kingdom| 635674609|            1.0|   0|\n",
      "|250000000| 112.31295|1084939099|    165|         7.6|    9106.0|         Action|  2012-07-16|      united_state| 834939099|            1.0|   0|\n",
      "|260000000| 43.926995| 284139100|    132|         6.1|    2124.0|         Action|  2012-03-07|      united_state|  24139100|            1.0|   0|\n",
      "|260000000| 48.681969| 591794936|    100|         7.4|    3330.0|      Animation|  2010-11-24|      united_state| 331794936|            1.0|   0|\n",
      "|280000000|134.279229|1405403694|    141|         7.3|    6767.0|         Action|  2015-04-22|      united_state|1125403694|            1.0|   0|\n",
      "|250000000| 98.885637| 933959197|    153|         7.4|    5293.0|      Advanture|  2009-07-07|    united_kingdom| 683959197|            1.0|   0|\n",
      "|250000000|155.790452| 873260194|    151|         5.7|    7004.0|         Action|  2016-03-23|      united_state| 623260194|            1.0|   0|\n",
      "|270000000| 57.925623| 391081192|    154|         5.4|    1400.0|         Action|  2006-06-28|      united_state| 121081192|            1.0|   0|\n",
      "|200000000|107.928811| 586090727|    106|         6.1|    2965.0|      Advanture|  2008-10-30|    united_kingdom| 386090727|            1.0|   0|\n",
      "|200000000|145.847379|1065659812|    151|         7.0|    5246.0|      Advanture|  2006-06-20|           jamaica| 865659812|            1.0|   0|\n",
      "|255000000| 49.046956|  89289910|    149|         5.9|    2311.0|         Action|  2013-07-03|      united_state|-165710090|            1.0|   2|\n",
      "|225000000| 99.398009| 662845518|    143|         6.5|    6359.0|         Action|  2013-06-12|    united_kingdom| 437845518|            1.0|   0|\n",
      "|225000000| 53.978602| 419651413|    150|         6.3|    1630.0|      Advanture|  2008-05-15|    czech republic| 194651413|            1.0|   0|\n",
      "|220000000|144.448633|1519557910|    143|         7.4|   11776.0|Science fiction|  2012-04-25|      united_state|1299557910|            1.0|   0|\n",
      "|380000000|135.413856|1045713802|    136|         6.4|    4948.0|      Advanture|  2011-05-14|      united_state| 665713802|            1.0|   0|\n",
      "|225000000| 52.035179| 624026776|    106|         6.2|    4160.0|         Action|  2012-05-23|      united_state| 399026776|            1.0|   0|\n",
      "|250000000|120.965743| 956019788|    144|         7.1|    4760.0|         Action|  2014-12-10|       new_zealand| 706019788|            1.0|   0|\n",
      "|215000000| 89.866276| 752215857|    136|         6.5|    6586.0|         Action|  2012-06-27|      united_state| 537215857|            1.0|   0|\n",
      "|200000000| 37.668301| 310669540|    140|         6.2|    1398.0|         Action|  2010-05-12|    united_kingdom| 110669540|            1.0|   0|\n",
      "+---------+----------+----------+-------+------------+----------+---------------+------------+------------------+----------+---------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
