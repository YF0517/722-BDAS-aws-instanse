{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d85fcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/21 08:14:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd77e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/transformed.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aa148b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- revenue: integer (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- vote_count: integer (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- production_country: string (nullable = true)\n",
      " |-- popularity_rank: string (nullable = true)\n",
      " |-- risk: string (nullable = true)\n",
      "\n",
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+\n",
      "|   budget|popularity|   revenue|runtime|vote_count|          genre|release_date|production_country|popularity_rank|risk|\n",
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+\n",
      "|300000000|139.082615| 961000000|    169|      4500|         Action|  2007-05-19|      united_state|           high| low|\n",
      "|245000000|107.376788| 880674609|    148|      4466|         Action|  2015-10-26|            others|           high| low|\n",
      "|250000000| 112.31295|1084939099|    165|      9106|         Action|  2012-07-16|      united_state|           high| low|\n",
      "|260000000| 43.926995| 284139100|    132|      2124|         Action|  2012-03-07|      united_state|           high| low|\n",
      "|260000000| 48.681969| 591794936|    100|      3330|      Animation|  2010-11-24|      united_state|           high| low|\n",
      "|280000000|134.279229|1405403694|    141|      6767|         Action|  2015-04-22|      united_state|           high| low|\n",
      "|250000000| 98.885637| 933959197|    153|      5293|      Advanture|  2009-07-07|            others|           high| low|\n",
      "|250000000|155.790452| 873260194|    151|      7004|         Action|  2016-03-23|      united_state|           high| low|\n",
      "|270000000| 57.925623| 391081192|    154|      1400|         Action|  2006-06-28|      united_state|           high| low|\n",
      "|200000000|107.928811| 586090727|    106|      2965|      Advanture|  2008-10-30|            others|           high| low|\n",
      "|200000000|145.847379|1065659812|    151|      5246|      Advanture|  2006-06-20|            others|           high| low|\n",
      "|255000000| 49.046956|  89289910|    149|      2311|         Action|  2013-07-03|      united_state|           high|high|\n",
      "|225000000| 99.398009| 662845518|    143|      6359|         Action|  2013-06-12|            others|           high| low|\n",
      "|225000000| 53.978602| 419651413|    150|      1630|      Advanture|  2008-05-15|            others|           high| low|\n",
      "|220000000|144.448633|1519557910|    143|     11776|Science fiction|  2012-04-25|      united_state|           high| low|\n",
      "|380000000|135.413856|1045713802|    136|      4948|      Advanture|  2011-05-14|      united_state|           high| low|\n",
      "|225000000| 52.035179| 624026776|    106|      4160|         Action|  2012-05-23|      united_state|           high| low|\n",
      "|250000000|120.965743| 956019788|    144|      4760|         Action|  2014-12-10|            others|           high| low|\n",
      "|215000000| 89.866276| 752215857|    136|      6586|         Action|  2012-06-27|      united_state|           high| low|\n",
      "|200000000| 37.668301| 310669540|    140|      1398|         Action|  2010-05-12|            others|           high| low|\n",
      "+---------+----------+----------+-------+----------+---------------+------------+------------------+---------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optionally, rename columns for better clarity\n",
    "df = df.withColumnRenamed(\"_c0\", \"budget\") \\\n",
    "       .withColumnRenamed(\"_c1\", \"popularity\") \\\n",
    "       .withColumnRenamed(\"_c2\", \"revenue\") \\\n",
    "       .withColumnRenamed(\"_c3\", \"runtime\") \\\n",
    "       .withColumnRenamed(\"_c4\", \"vote_count\") \\\n",
    "       .withColumnRenamed(\"_c5\", \"genre\") \\\n",
    "       .withColumnRenamed(\"_c6\", \"release_date\") \\\n",
    "       .withColumnRenamed(\"_c7\", \"production_country\")\\\n",
    "       .withColumnRenamed(\"_c8\", \"popularity_rank\")\\\n",
    "       .withColumnRenamed(\"_c9\", \"risk\")\n",
    "# Let's get an idea of what the data looks like. \n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad01e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# Convert categorical columns into numerical representations\n",
    "indexer_genre = StringIndexer(inputCol=\"genre\", outputCol=\"genre_index\")\n",
    "indexer_country = StringIndexer(inputCol=\"production_country\", outputCol=\"country_index\")\n",
    "indexer_risk = StringIndexer(inputCol=\"risk\", outputCol=\"risk_index\")\n",
    "indexer_rank = StringIndexer(inputCol=\"popularity_rank\", outputCol=\"rank_index\")\n",
    "\n",
    "# Apply StringIndexer transformations\n",
    "df = indexer_genre.fit(df).transform(df)\n",
    "df = indexer_country.fit(df).transform(df)\n",
    "df = indexer_risk.fit(df).transform(df)\n",
    "df = indexer_rank.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0188b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 08:15:48 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "24/05/21 08:15:48 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "24/05/21 08:15:48 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/05/21 08:15:48 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "24/05/21 08:15:48 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/05/21 08:15:48 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.clustering import GaussianMixture\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Gaussian Mixture Model\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load data\n",
    "data = df\n",
    "\n",
    "# Preprocess data and create feature vector\n",
    "feature_cols = feature_cols = ['genre_index',\"country_index\",\"risk_index\",\"rank_index\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Train GMM model\n",
    "gmm = GaussianMixture(k=3, seed=1)  # Specify the number of clusters (k)\n",
    "model = gmm.fit(data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(data)\n",
    "\n",
    "# Evaluate model (optional)\n",
    "# [Add code for evaluation if needed]\n",
    "\n",
    "# Save or export results\n",
    "# [Add code for saving or exporting results]\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
